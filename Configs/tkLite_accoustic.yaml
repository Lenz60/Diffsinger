base_config:
  - configs/base.yaml

task_cls: training.acoustic_task.AcousticTask

dictionaries:
  jp: "Z:/Diffsinger/local_env_setup/DiffSinger/dictionaries/tk_dictionary.txt"
extra_phonemes: []
merged_phoneme_groups: []

# ✅ Define datasets as a list of objects
datasets:
  - speaker: "Taka" # or "speaker" depending on your repo; both are accepted in OpenVPI
    spk_id: 0 # single-speaker
    language: "jp"
    raw_data_dir: "data/training_data/TakaLite"
    binary_data_dir: "data/binary/tk_accoustic/TakaLite"
    test_prefixes:
      - "1_seg000"
      - "1_seg001"
      - "2_seg001"
      - "3_seg000"

# Trainer / frontend
accelerator: gpu
devices: 1
pl_trainer_precision: "16-mixed"

num_workers: 6
pin_memory: true
dataloader_prefetch_factor: 2
persistent_workers: true

# pl_trainer_precision: "16-mixed"
pe: "rmvpe"
pe_ckpt: "Z:/Diffsinger/local_env_setup/DiffSinger/checkpoints/rmvpe/model.pt"

hnsep: world # <— make sure your fork reads this name; see tip below

# test_prefixes:
#   - 0:3_seg032
#   - 0:6_seg006
#   - 0:8_seg034

# Vocoder & audio
vocoder: NsfHifiGAN
vocoder_ckpt: "checkpoints/nsf_hifigan/model"
audio_sample_rate: 44100
audio_num_mel_bins: 128
hop_size: 512
fft_size: 2048
win_size: 2048
fmin: 40
fmax: 16000

# Binarization & augmentation
binarization_args:
  shuffle: true
  num_workers: 6
augmentation_args:
  random_pitch_shifting:
    enabled: false
    range: [-5., 5.]
    scale: 0.75
  fixed_pitch_shifting:
    enabled: false
    targets: [-5., 5.]
    scale: 0.5
  random_time_stretching:
    enabled: false
    range: [0.5, 2.]
    scale: 0.75

# (Global binary dir is optional when you already set per-dataset binary_data_dir)
binary_data_dir: "data/binary/tk_accoustic/"
binarizer_cls: preprocessing.acoustic_binarizer.AcousticBinarizer

# Spectrogram ranges
spec_min: [-12]
spec_max: [0]
mel_vmin: -14.
mel_vmax: 4.
mel_base: "e"

# Variance embeds (disabled for now)
use_lang_id: false
num_lang: 1
use_spk_id: true
num_spk: 1
use_energy_embed: false
use_breathiness_embed: false
use_voicing_embed: false
use_tension_embed: false
use_key_shift_embed: false
use_speed_embed: false

# Diffusion / RF settings
diffusion_type: reflow
time_scale_factor: 1000
timesteps: 1000
max_beta: 0.02
enc_ffn_kernel_size: 3
use_rope: true
rel_pos: true
sampling_algorithm: euler
sampling_steps: 20
diff_accelerator: ddim
diff_speedup: 10
hidden_size: 256
backbone_type: "lynxnet"
backbone_args:
  num_channels: 1024
  num_layers: 6
  kernel_size: 31
  dropout_rate: 0.0
  strong_cond: true
main_loss_type: l2
main_loss_log_norm: false
schedule_type: "linear"

# Shallow diffusion
use_shallow_diffusion: true
T_start: 0.4
T_start_infer: 0.4
K_step: 400
K_step_infer: 400
shallow_diffusion_args:
  train_aux_decoder: true
  train_diffusion: true
  val_gt_start: false
  aux_decoder_arch: convnext
  aux_decoder_args:
    num_channels: 512
    num_layers: 6
    kernel_size: 7
    dropout_rate: 0.1
  aux_decoder_grad: 0.1
lambda_aux_mel_loss: 0.2

# Train & eval
num_sanity_val_steps: 1
optimizer_args:
  lr: 0.0006
lr_scheduler_args:
  step_size: 10000
  gamma: 0.75
max_batch_frames: 50000
max_batch_size: 2
dataset_size_key: "lengths"
val_with_vocoder: true
val_check_interval: 1000
num_valid_plots: 10
max_updates: 160000
num_ckpt_keep: 20
permanent_ckpt_start: 80000
permanent_ckpt_interval: 20000

# Finetune / freezing (off)
finetune_enabled: false
finetune_ckpt_path: null
finetune_ignored_params:
  - model.fs2.encoder.embed_tokens
  - model.fs2.txt_embed
  - model.fs2.spk_embed
finetune_strict_shapes: true

freezing_enabled: false
frozen_params: []
